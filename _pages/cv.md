---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
======
* M.S. in Information Technology & Management, [The University of Texas at Dallas](https://www.utdallas.edu/), 2020 
* B.Tech. in Computer Engineering, [University of Mumbai](https://mu.ac.in/), 2017

Skills
======
* Analytical Tools: Tableau, Excel (LOOKUP, Pivot Table, Charts, INDEX MATCH), QlikView, SAS, Power BI, SSMS, SSRS, Looker 
* Databases: MySQL, PostgreSQL, Oracle, MS SQL, Dremio SQL 
* Programming: Python (Pandas, Matplotlib, NumPy), R, SQL, PL/SQL, Java, HTML, Bootstrap, LookML, Airflow, Segment 
* Machine Learning: Regression, Time Series, Classification, Clustering, ARIMA, KNN, ANOVA 
* Project Management: JIRA, Alation, Lucid Chart, Confluence, Notion 
* Certifications: Tableau for Data Science, Machine Learning A-Z, Master SQL for Data Science, Google Ad Grants

Industrial Experience
======
* Data Management Analyst, Avant, Apr 2022 - Jun 2023
  * Designed the new customer explore in Looker using LookML for business users to generate daily and weekly dashboards
  *	Migrated data automated jobs to push data into Segment (CDP) for 4 marketing campaigns using Python and SQL
  *	Curated data catalog documentation for customer datasets in Alation to provide more information to business users
  *	Performed validations on 6 automated data jobs to ensure data consistency and accuracy for existing marketing campaigns using SQL
  *	Implemented 30 + data validations in test, UAT, and PROD environments for customer data pipeline changes using SQL
  *	Designed and assisted the business with SQL scripts for advanced, ad hoc analytical use cases to facilitate required data 
  *	Performed data audit on data fields for customer datasets to ensure consistent data migration via Python and SQL
  *	Executed an investigative analysis to understand the patterns in missing data from the deliverables for the customer pipeline
  
* Data Analyst, The University of Texas at Austin - Office of Strategy & Policy, Jan 2021 - Mar 2022
  *	Executed data extraction pipeline on Microsoft Azure to perform weekly refresh of data for maintaining data integrity
  *	Designed College Career Knowledge Assessment reports of 20 districts for the academic year 2021 using SSMS & SSRS
  *	Modeled and visualized 4 PLI reports for the Quality Control Process by mapping 200 stored procedures in SSMS & SSRS
  *	Drafted and executed 30 + ad hoc data requests SQL scripts to provide required data to various stakeholders
  *	Designed End of Year reports for 197 districts by constructing charts and developing stored procedures in SSRS & SSMS
  *	Extracted around 1 million course data by devising a web scrapping script in Python using the Selenium automation package
  *	Constructed College Career Knowledge Assessment reports for 52 districts by implementing stored procedures in SSRS
  *	Modeled database schema diagram to reflect new changes in internal database structure for the MapMyPath project
  *	Performed Quality Control Process for around 30 Middle of Year reports and assisted in End of Course Assessment testing

* Assistant System Engineer, Tata Consultancy Services, Dec 2017 - Jun 2018
  *	Analyzed and reported the number of weekly hours saved in Sanity and Load Testing triage by generating ad-hoc reports
  *	Enhanced product quality in concurrent sprints by fetching data via SQL and developing dashboards on MS Excel
  *	Performed scaled automation using Python test framework, resulting in a 10% increase in defect identification across SKUs
  *	Developed automated Python script for Sanity and Load Testing failure triage process, reducing manual efforts by 18%
  *	Devised end-to-end testing on storage systems project by designing several automation test scripts using selenium 
  *	Reviewed new areas of opportunity in daily agile standup meetings with team leads, product owners, and stakeholders
 
Projects
======
* Frito-Lay Data Analysis Using Microsoft Excel & SAS, Mar 2020 - May 2020
  * Performed ad hoc data analysis on 9 million records to visualize market share and weekly sales by product categories
  * Identified key factors affecting the odds of people buying Fritos products by designing a multinomial logit model with 83% accuracy
  * Forecasted overall sales of the Fritos brand and drilled down the forecasting on market and product level using the ARIMA model
  * Predicted number of units at market level for various product types to efficiently manage inventory across 140 locations
  * Utilized demographics coupled with customer segments using Recency Frequency Monetary analysis to get crucial insights 
  
* Predictive Analytics Using SAP Business Objects, Nov 2019 - Dec 2019
  * Estimated the future value of liquid assets by performing a time series analysis of the cash flow data
  * Created interaction variables to reduce forecasting error of the predictive model by 6.8%
  * Established rules for customer search patterns and constructed a flow graph by conducting association rule mining
  * Predicted number of customers responding to the promotional offer with 91.97% accuracy by defining a classification model

* Walmart Sales Prediction Using Python, Apr 2019 – Jun 2019
  * Analyzed the impact of Markdown values and Holidays on Weekly Sales of various departments for 45 Walmart stores
  * Forecasted overall sales for 3 months by store type using Auto-ARIMA predictive model with RMSE of 407.8 units
  * Improved accuracy of sales forecast by implementing GRU predictive model to reduce the root mean square error by 6.14%
  * Created an ensemble regression model by taking an average of regressors to reduce RMSE and improve accuracy to 97.18 % 

* Exploratory Data Analysis Using Tableau & Hive, Apr 2019 – Jun 2019
  * Imported geolocation and truck information data into the Hadoop File System by incorporating external tables using Hive
  * Eliminated the skewness in the data by identifying and normalizing risk factor associated with truck accidents
  * Identified cities prone to high number of accidents by integrating Apache Hadoop with Tableau dashboards

* Bitcoin Price Prediction Using ARIMA Forecasting in R, Mar 2019
  * Utilized cryptocurrency, crude oil, and stock price variables to improve the forecasting accuracy of bitcoin prices by 9%
  * Visualized periodogram and analyzed results to identify the trends in bitcoin prices based on seasonality 
  * Optimized ARIMA model to efficiently forecast bitcoin prices and visualized the predicted results using ggplot2

* Google AdWords Campaign, Feb 2019 – Mar 2019
  * Strategized SEM campaigns for Thea’s Star of Hope to increase brand awareness and donations towards cancer research studies
  * Optimized bidding strategies by conducting adequate keyword research and improving the quality score of the ads
  * Improved click-through rate (CTR) of a brand awareness campaign by 5.12%
  * Designed dynamic ad groups for an awareness campaign, leading to a click-through rate (CTR) of 45.94%

* Sales Prediction Using Multi-Linear Regression Analysis, Mar 2019
  * Predicted the price based on customer demographics by extracting and cleaning 2 million records of Black Friday Sales
  * Improved fitness of multi-linear regression model by 7.5% using advanced techniques like backward elimination

* Accio Viand Food Ordering App, Aug 2018 – Dec 2018
  * Produced a system analysis report by employing project management tools and techniques.
  * Identified functional and non-functional requirements and modeled an information system by designing UML diagrams

* Visual Analysis of Natural Disasters at ConocoPhillips Refineries Locations, Oct 2018
  * Performed an exploratory design analysis on different Conoco Phillips Refineries locations
  * Designed a narrative visualization of refineries by developing a dashboard of different story points and annotations
  * Cataloged appropriate rhetoric and established a connected relationship between the story points

* Standards Elimination Parser Using Natural Language Processing
  * Designed a parser for converting the Units/standards to the intended standards as required by the user
  * Engineered logic for a method used for converting words to numbers like four hundred gets converted to 400
  * Strategized and implemented logic for conversion of time as per the required time zone

 
<!---
Publications
======
  <ul>{% for post in site.publications %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>
  
Talks
======
  <ul>{% for post in site.talks %}
    {% include archive-single-talk-cv.html %}
  {% endfor %}</ul>
  
Teaching
======
  <ul>{% for post in site.teaching %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>
  
Service and leadership
======
* Currently signed in to 43 different slack teams
-->
